{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GvHk5Kx69ztK"
      },
      "outputs": [],
      "source": [
        "!gdown -q 1T6-AojJ-2ZwCR4X_SMeA5xmek7JLtolv\n",
        "!unzip -q TruckDataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install torchview\n",
        "!pip -q install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUiRNJhy-rWk",
        "outputId": "4fc31e43-ce7d-4e1b-c3c8-26b86fcf933f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchview import draw_graph\n",
        "from ultralytics import YOLO\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset_path = \"/content/Dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDUwZCP3-hYH",
        "outputId": "185b28ee-f37d-49dd-b720-795d09dce297"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def read_image(img_path, yolo=False):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    img = transform(img)\n",
        "    img = img.to(torch.float32)\n",
        "    img = img.to(device)\n",
        "    return img\n",
        "\n",
        "def make_prediction(model, img):\n",
        "    if type(model) == YOLO:\n",
        "        results = model.predict(img, save=False, verbose=False)\n",
        "        return len(results[0].boxes)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img.unsqueeze(0))\n",
        "        return outputs[0][0].item()\n",
        "\n",
        "\n",
        "def evaluate(model, yolo=False):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    print(\"Real value - Rounded prediction - Original prediction\")\n",
        "    with open(dataset_path+\"/test/number_of_axles_test.txt\", 'r') as f:\n",
        "        for i in f.readlines():\n",
        "            img_path, label = i.split(\",\")\n",
        "            label = int(label)\n",
        "\n",
        "            y_true.append(label)\n",
        "\n",
        "            img = os.path.join(dataset_path+\"test/images\", img_path)\n",
        "            if not yolo:\n",
        "                img = read_image(img)\n",
        "\n",
        "            prediction = make_prediction(model, img)\n",
        "            round_prediction = round(prediction)\n",
        "            y_pred.append(round_prediction)\n",
        "\n",
        "            if round_prediction != label:\n",
        "                print(f\"{label}: {round_prediction} - {prediction}\")\n",
        "\n",
        "    precision, recall, f1score, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1score}\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fWKKoiT0_zlk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inception"
      ],
      "metadata": {
        "id": "6a3IZzp4DHvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InceptionModel, self).__init__()\n",
        "\n",
        "        self.model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
        "        self.model.aux_logits = False\n",
        "\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Linear(256, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "inception = InceptionModel()\n",
        "inception = inception.to(device)\n",
        "inception.load_state_dict(torch.load(\"inception.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIrnQ6NG-fKm",
        "outputId": "9e72c21e-6c29-42f6-9d40-c6d47440310e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-cc6ada57671e>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  inception.load_state_dict(torch.load(\"inception.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(inception)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKFRocHWCqz5",
        "outputId": "9403bc51-26bd-4015-9a29-286666f97fe6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real value - Rounded prediction - Original prediction\n",
            "7: 6 - 5.939828395843506\n",
            "5: 4 - 4.160600662231445\n",
            "3: 4 - 3.604426860809326\n",
            "3: 2 - 2.1354315280914307\n",
            "4: 3 - 3.136538028717041\n",
            "6: 5 - 4.732193946838379\n",
            "7: 6 - 6.214473724365234\n",
            "4: 2 - 2.334242820739746\n",
            "\n",
            "Precision: 0.8796660532167778\n",
            "Recall: 0.8519126854233238\n",
            "F1 Score: 0.8613615476518702\n",
            "Accuracy: 0.926605504587156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50"
      ],
      "metadata": {
        "id": "ZNwZn1VnDJ0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.model = models.resnet50(weights=(models.ResNet50_Weights.IMAGENET1K_V1))\n",
        "\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Linear(256, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "resnet = ResNet()\n",
        "resnet = resnet.to(device)\n",
        "resnet.load_state_dict(torch.load(\"resnet50.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjr_CREtDLmp",
        "outputId": "110ed869-7673-4018-f763-c6a5d61c4e78"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-596f25acd43e>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  resnet.load_state_dict(torch.load(\"resnet50.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(resnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8df4msRDa_I",
        "outputId": "e119bd68-a139-44c5-c240-5d80fac48836"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real value - Rounded prediction - Original prediction\n",
            "5: 6 - 5.994332790374756\n",
            "5: 6 - 6.022765159606934\n",
            "6: 7 - 6.539203643798828\n",
            "2: 3 - 2.660851001739502\n",
            "3: 2 - 2.2596256732940674\n",
            "3: 4 - 3.546790361404419\n",
            "3: 4 - 3.6322436332702637\n",
            "5: 6 - 5.630774974822998\n",
            "6: 5 - 5.450976371765137\n",
            "4: 3 - 3.3756537437438965\n",
            "4: 3 - 3.497750997543335\n",
            "3: 4 - 3.558598279953003\n",
            "4: 5 - 4.8895416259765625\n",
            "4: 3 - 3.0367188453674316\n",
            "\n",
            "Precision: 0.7672982868195634\n",
            "Recall: 0.7785079105291871\n",
            "F1 Score: 0.7713121138406368\n",
            "Accuracy: 0.8715596330275229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo"
      ],
      "metadata": {
        "id": "vUfvslj6DhTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo = YOLO(\"best.pt\")"
      ],
      "metadata": {
        "id": "-96CijfJEtgS"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model=yolo, yolo=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43n-w1AXE9SG",
        "outputId": "5c83433e-3df3-4976-8868-ee7c6809fe33"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real value - Rounded prediction - Original prediction\n",
            "2: 3 - 3\n",
            "2: 4 - 4\n",
            "3: 4 - 4\n",
            "4: 5 - 5\n",
            "\n",
            "Precision: 0.9280778323331514\n",
            "Recall: 0.9497872340425532\n",
            "F1 Score: 0.9373882441435634\n",
            "Accuracy: 0.963302752293578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val(data=\"Dataset/teste.yaml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVkH4923HihN",
        "outputId": "2aef71b0-0fa4-4c53-c35e-440935930f8d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.70 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 18.7MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/test/labels... 109 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:00<00:00, 1092.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/test/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        109        398      0.994      0.995      0.995       0.77\n",
            "Speed: 4.5ms preprocess, 25.5ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mAP50-95 : {metrics.box.map}\")\n",
        "print(f\"mAP50    : {metrics.box.map50}\")\n",
        "print(f\"mAP75    : {metrics.box.map75}\")\n",
        "print(f\"Precision: {metrics.box.p[0]}\")\n",
        "print(f\"Recall   : {metrics.box.r[0]}\")\n",
        "print(f\"F1 Score : {metrics.box.f1[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrok1h0nHs9A",
        "outputId": "744f4463-5997-4f94-a8ee-077b4974c71b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP50-95 : 0.7700400536318341\n",
            "mAP50    : 0.994899115832326\n",
            "mAP75    : 0.9399364363157161\n",
            "Precision: 0.9944383623267529\n",
            "Recall   : 0.9949748743718593\n",
            "F1 Score : 0.9947065460050668\n"
          ]
        }
      ]
    }
  ]
}