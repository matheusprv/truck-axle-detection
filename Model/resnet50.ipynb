{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import cv2\n",
                "import torch\n",
                "import numpy as np\n",
                "import random\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision import models, transforms\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CustomDataset(Dataset):\n",
                "    def __init__(self, imgs_folder, labels_txt):\n",
                "        self.transform = transforms.Compose([\n",
                "            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "        ])\n",
                "        self.dataset = []\n",
                "        with open(labels_txt, 'r') as f:\n",
                "            for line in f.readlines():\n",
                "                img_file, label = line.split(\",\")\n",
                "                img_file = os.path.join(imgs_folder, img_file)\n",
                "                label = int(label)\n",
                "                self.dataset.append((img_file, label))\n",
                "\n",
                "        random.shuffle(self.dataset)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.dataset)\n",
                "\n",
                "    def __getitem__(self, index):\n",
                "        img_path, label = self.dataset[index]\n",
                "        img = cv2.imread(img_path)\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n",
                "\n",
                "        img = self.transform(img)\n",
                "        img = img.to(torch.float32)\n",
                "\n",
                "        label = torch.tensor(label, dtype=torch.float32)\n",
                "        return img, label"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_path = \"/media/work/matheusvieira/truck_axle/Dataset/\"\n",
                "train_dataset = CustomDataset(dataset_path + \"train/images\", dataset_path + \"train/number_of_axles_train.txt\")\n",
                "valid_dataset = CustomDataset(dataset_path + \"valid/images\", dataset_path + \"valid/number_of_axles_valid.txt\")\n",
                "test_dataset = CustomDataset(dataset_path + \"test/images\", dataset_path + \"test/number_of_axles_test.txt\")\n",
                "\n",
                "BATCH_SIZE = 8\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
                "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
                "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SequentialModel(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(SequentialModel, self).__init__()\n",
                "        self.model = models.resnet50(weights=(models.ResNet50_Weights.IMAGENET1K_V1))\n",
                "\n",
                "        self.model.fc = nn.Sequential(\n",
                "            nn.Linear(2048, 512),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(512, 256),\n",
                "            nn.ReLU(),\n",
                "            nn.BatchNorm1d(256),\n",
                "            nn.Linear(256, 32),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(32, 1)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.model(x)\n",
                "        return x\n",
                "\n",
                "# Instantiate the model\n",
                "model = SequentialModel()\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "model = model.to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1, Train Loss: 2.7785, Train MAE: 1.2115, Val Loss: 3.7671, Val MAE Loss: 0.1768\n",
                        "Best model saved at epoch 1\n",
                        "Epoch 2, Train Loss: 1.1118, Train MAE: 0.7761, Val Loss: 0.3003, Val MAE Loss: 0.0504\n",
                        "Best model saved at epoch 2\n",
                        "Epoch 3, Train Loss: 0.7028, Train MAE: 0.6251, Val Loss: 0.3699, Val MAE Loss: 0.0556\n",
                        "Epoch 4, Train Loss: 0.4465, Train MAE: 0.4933, Val Loss: 0.3923, Val MAE Loss: 0.0566\n",
                        "Epoch 5, Train Loss: 0.4312, Train MAE: 0.4799, Val Loss: 0.1891, Val MAE Loss: 0.0389\n",
                        "Best model saved at epoch 5\n",
                        "Epoch 6, Train Loss: 0.3609, Train MAE: 0.4449, Val Loss: 0.1889, Val MAE Loss: 0.0394\n",
                        "Best model saved at epoch 6\n",
                        "Epoch 7, Train Loss: 0.3590, Train MAE: 0.4303, Val Loss: 0.3723, Val MAE Loss: 0.0478\n",
                        "Epoch 8, Train Loss: 0.3234, Train MAE: 0.4113, Val Loss: 0.3177, Val MAE Loss: 0.0496\n",
                        "Epoch 9, Train Loss: 0.2134, Train MAE: 0.3397, Val Loss: 0.1547, Val MAE Loss: 0.0349\n",
                        "Best model saved at epoch 9\n",
                        "Epoch 10, Train Loss: 0.1557, Train MAE: 0.2911, Val Loss: 0.1658, Val MAE Loss: 0.0354\n",
                        "Epoch 11, Train Loss: 0.1742, Train MAE: 0.3065, Val Loss: 0.1495, Val MAE Loss: 0.0343\n",
                        "Best model saved at epoch 11\n",
                        "Epoch 12, Train Loss: 0.1517, Train MAE: 0.2888, Val Loss: 0.1211, Val MAE Loss: 0.0308\n",
                        "Best model saved at epoch 12\n",
                        "Epoch 13, Train Loss: 0.1344, Train MAE: 0.2727, Val Loss: 0.1285, Val MAE Loss: 0.0303\n",
                        "Epoch 14, Train Loss: 0.1219, Train MAE: 0.2545, Val Loss: 0.1854, Val MAE Loss: 0.0392\n",
                        "Epoch 15, Train Loss: 0.0834, Train MAE: 0.2152, Val Loss: 0.1177, Val MAE Loss: 0.0279\n",
                        "Best model saved at epoch 15\n",
                        "Epoch 16, Train Loss: 0.0888, Train MAE: 0.2175, Val Loss: 0.2967, Val MAE Loss: 0.0461\n",
                        "Epoch 17, Train Loss: 0.1069, Train MAE: 0.2338, Val Loss: 0.2411, Val MAE Loss: 0.0418\n",
                        "Epoch 18, Train Loss: 0.0832, Train MAE: 0.2150, Val Loss: 0.2429, Val MAE Loss: 0.0407\n",
                        "Early stopping\n"
                    ]
                }
            ],
            "source": [
                "criterion = nn.MSELoss()\n",
                "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
                "MAE = nn.L1Loss()\n",
                "\n",
                "best_val_loss = float('inf')\n",
                "patience = 3\n",
                "counter = 0\n",
                "\n",
                "for epoch in range(25):\n",
                "    model.train()\n",
                "    train_loss = 0.0\n",
                "    mae_train_loss = 0.0\n",
                "\n",
                "    for images, labels in train_loader:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs.squeeze(), labels)\n",
                "        mae_loss = MAE(outputs.squeeze(), labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "        train_loss += loss.item() * images.size(0)\n",
                "        mae_train_loss += mae_loss.item() * images.size(0)\n",
                "\n",
                "    train_loss /= len(train_loader.dataset)\n",
                "    mae_train_loss /= len(train_loader.dataset)\n",
                "\n",
                "    # Validation\n",
                "    model.eval()\n",
                "    val_loss = 0.0\n",
                "    mae_val_loss = 0.0\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for images, labels in valid_loader:\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs.squeeze(), labels)\n",
                "            mae_loss = MAE(outputs.squeeze(), labels)\n",
                "\n",
                "            val_loss += loss.item() * images.size(0)\n",
                "            mae_val_loss += mae_loss.item() * images.size(0)\n",
                "\n",
                "    val_loss /= len(valid_loader.dataset)\n",
                "    mae_val_loss /= len(valid_loader.dataset)\n",
                "\n",
                "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train MAE: {mae_train_loss:.4f}, Val Loss: {val_loss:.4f}, Val MAE Loss: {mae_val_loss:.4f}\")\n",
                "\n",
                "    if val_loss < best_val_loss:\n",
                "        best_val_loss = val_loss\n",
                "        counter = 0\n",
                "        torch.save(model.state_dict(), f\"best_resnet.pth\")\n",
                "        print(f\"Best model saved at epoch {epoch+1}\")\n",
                "    else:\n",
                "        counter += 1\n",
                "        if counter >= patience:\n",
                "            print(\"Early stopping\")\n",
                "            model.load_state_dict(torch.load(f\"best_resnet.pth\"))\n",
                "            break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test Loss: 0.1081 - Test MAE Loss: 0.2362\n"
                    ]
                }
            ],
            "source": [
                "model.eval()\n",
                "test_loss = 0.0\n",
                "test_mae_loss = 0.0\n",
                "\n",
                "with torch.no_grad():\n",
                "    for images, labels in test_loader:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs.squeeze(), labels)\n",
                "        mae = MAE(outputs.squeeze(), labels)\n",
                "\n",
                "        test_loss += loss.item() * images.size(0)\n",
                "        test_mae_loss += mae.item() * images.size(0)\n",
                "\n",
                "test_loss /= len(test_loader.dataset)\n",
                "test_mae_loss /= len(test_loader.dataset)\n",
                "\n",
                "print(f\"Test Loss: {test_loss:.4f} - Test MAE Loss: {test_mae_loss:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_prediction(model, img_path):\n",
                "    img = cv2.imread(img_path)\n",
                "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n",
                "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
                "    img = transform(img)\n",
                "    img = img.to(torch.float32)\n",
                "    img = img.to(device)\n",
                "\n",
                "    with torch.no_grad():\n",
                "        outputs = model(img.unsqueeze(0))\n",
                "        return outputs[0][0].item()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "5: 6 - 5.994604110717773\n",
                        "5: 6 - 6.022638320922852\n",
                        "6: 7 - 6.538928985595703\n",
                        "2: 3 - 2.661052703857422\n",
                        "3: 2 - 2.2592077255249023\n",
                        "3: 4 - 3.547114372253418\n",
                        "3: 4 - 3.6323678493499756\n",
                        "5: 6 - 5.631110191345215\n",
                        "6: 5 - 5.450845718383789\n",
                        "4: 3 - 3.375753879547119\n",
                        "4: 3 - 3.4980804920196533\n",
                        "3: 4 - 3.5585689544677734\n",
                        "4: 5 - 4.889366149902344\n",
                        "4: 3 - 3.036308765411377"
                    ]
                }
            ],
            "source": [
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "y_true = []\n",
                "y_pred = []\n",
                "\n",
                "with open(dataset_path+\"test/number_of_axles_test.txt\", 'r') as f:\n",
                "    for i in f.readlines():\n",
                "        img_file, label = i.split(\",\")\n",
                "        y_true.append(int(label))\n",
                "\n",
                "        img_file = os.path.join(dataset_path+\"/test/images\", img_file)\n",
                "\n",
                "        no_round = make_prediction(model, img_file)\n",
                "        predicao = round(no_round)\n",
                "        if predicao != int(label):\n",
                "            print(f\"{int(label)}: {predicao} - {no_round}\")\n",
                "        y_pred.append(predicao)\n",
                "\n",
                "confusion_matrix(y_true, y_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(0.7672982868195634, 0.7785079105291871, 0.7713121138406368, None)\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.metrics import precision_recall_fscore_support\n",
                "print(precision_recall_fscore_support(y_true, y_pred, average=\"macro\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.8715596330275229"
                    ]
                }
            ],
            "source": [
                "from sklearn.metrics import accuracy_score\n",
                "print(accuracy_score(y_true, y_pred))"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
